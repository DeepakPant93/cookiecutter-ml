{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":".md-typeset h1, .md-content__button { display: none; } Cookiecutter Machine Learning Template \u00b6 This is a modern Cookiecutter template for initializing Python projects, particularly for machine learning . It provides a comprehensive setup for development, testing, and deployment, incorporating essential tools for effective project management. Features \u00b6 This template includes the following features: Poetry for dependency management CI/CD with GitHub Actions Pre-commit hooks using pre-commit Code quality checks with ruff , mypy , deptry , and prettier Publishing to PyPI via GitHub releases Testing and coverage with pytest and codecov Documentation generation with MkDocs Python compatibility testing with Tox Containerization using Docker Development environment with VSCode devcontainers Deployment with Azure Container Apps Data Version Control (DVC) support for managing data files ( DVC Docs ) You can find an example repository created using this template here . Quickstart \u00b6 To get started, follow these steps: Step 1: Install cookiecutter-ml \u00b6 First, navigate to the directory where you want to create the project and run: pip install cookiecutter-ml Alternatively, you can install cookiecutter and use the GitHub repository URL directly: pip install cookiecutter cookiecutter git@github.com:DeepakPant93/cookiecutter-poetry.git Step 2: Create a GitHub Repository \u00b6 Create a new repository on GitHub, then run the following commands in your terminal, replacing <project-name> with your GitHub repository name and <github_author_handle> with your GitHub username: cd <project_name> git init -b main git add . git commit -m \"Initial commit\" git remote add origin git@github.com:<github_author_handle>/<project_name>.git git push -u origin main Step 3: Install the Environment and Pre-commit Hooks \u00b6 Run the following command to install the environment and pre-commit hooks: make bake-env Now you're all set to start development! The CI/CD pipeline will automatically trigger on pull requests, merges to the main branch, and new releases. For instructions on publishing to PyPI , refer to this guide . To enable automatic documentation with MkDocs , follow the steps in this guide . For code coverage setup, refer to this guide . Acknowledgements \u00b6 This project is inspired by Audrey Feldroy's excellent work on the cookiecutter-pypackage template.","title":"Home"},{"location":"#cookiecutter-machine-learning-template","text":"This is a modern Cookiecutter template for initializing Python projects, particularly for machine learning . It provides a comprehensive setup for development, testing, and deployment, incorporating essential tools for effective project management.","title":"Cookiecutter Machine Learning Template"},{"location":"#features","text":"This template includes the following features: Poetry for dependency management CI/CD with GitHub Actions Pre-commit hooks using pre-commit Code quality checks with ruff , mypy , deptry , and prettier Publishing to PyPI via GitHub releases Testing and coverage with pytest and codecov Documentation generation with MkDocs Python compatibility testing with Tox Containerization using Docker Development environment with VSCode devcontainers Deployment with Azure Container Apps Data Version Control (DVC) support for managing data files ( DVC Docs ) You can find an example repository created using this template here .","title":"Features"},{"location":"#quickstart","text":"To get started, follow these steps:","title":"Quickstart"},{"location":"#step-1-install-cookiecutter-ml","text":"First, navigate to the directory where you want to create the project and run: pip install cookiecutter-ml Alternatively, you can install cookiecutter and use the GitHub repository URL directly: pip install cookiecutter cookiecutter git@github.com:DeepakPant93/cookiecutter-poetry.git","title":"Step 1: Install cookiecutter-ml"},{"location":"#step-2-create-a-github-repository","text":"Create a new repository on GitHub, then run the following commands in your terminal, replacing <project-name> with your GitHub repository name and <github_author_handle> with your GitHub username: cd <project_name> git init -b main git add . git commit -m \"Initial commit\" git remote add origin git@github.com:<github_author_handle>/<project_name>.git git push -u origin main","title":"Step 2: Create a GitHub Repository"},{"location":"#step-3-install-the-environment-and-pre-commit-hooks","text":"Run the following command to install the environment and pre-commit hooks: make bake-env Now you're all set to start development! The CI/CD pipeline will automatically trigger on pull requests, merges to the main branch, and new releases. For instructions on publishing to PyPI , refer to this guide . To enable automatic documentation with MkDocs , follow the steps in this guide . For code coverage setup, refer to this guide .","title":"Step 3: Install the Environment and Pre-commit Hooks"},{"location":"#acknowledgements","text":"This project is inspired by Audrey Feldroy's excellent work on the cookiecutter-pypackage template.","title":"Acknowledgements"},{"location":"prompt_arguments/","text":"Prompt Arguments \u00b6 When you run the cookiecutter command, you'll be prompted to configure your repository with various input values. Here\u2019s an explanation of each prompt value: author \u00b6 Your full name. email \u00b6 Your email address. author_github_handle \u00b6 Your GitHub handle, i.e., <handle> in https://github.com/<handle> . project_name \u00b6 The name of your project. This should match the repository name and contain only alphanumeric characters and hyphens ( - ). project_slug \u00b6 A slug for your project. By default, this is derived from project_name with hyphens ( - ) replaced by underscores ( _ ). This is used for importing code, e.g.: from <project_slug> import foo project_description \u00b6 A brief description of your project. dockerhub_username \u00b6 Your Docker Hub username, i.e., <handle> in https://hub.docker.com/u/<handle> . include_github_actions \u00b6 Set this to \"y\" or \"n\" . If enabled, a .github directory will be created with actions and workflows for setting up the environment, running code formatting checks, and executing unit tests. data_source_type \u00b6 Specifies the type of data source for your project. Options: [\"1. Google Drive\"] data_source_id \u00b6 The identifier for your data source, such as a folder ID or bucket name, where data is stored for model training. app_host_port \u00b6 The port on which the application will run. Defaults to 80 . open_source_license \u00b6 Select a license for your project. Options include: [\"1. MIT License\", \"2. BSD license\", \"3. ISC license\", \"4. Apache Software License 2.0\", \"5. GNU General Public License v3\", \"6. Not open source\"]","title":"Prompt Arguments"},{"location":"prompt_arguments/#prompt-arguments","text":"When you run the cookiecutter command, you'll be prompted to configure your repository with various input values. Here\u2019s an explanation of each prompt value:","title":"Prompt Arguments"},{"location":"prompt_arguments/#author","text":"Your full name.","title":"author"},{"location":"prompt_arguments/#email","text":"Your email address.","title":"email"},{"location":"prompt_arguments/#author_github_handle","text":"Your GitHub handle, i.e., <handle> in https://github.com/<handle> .","title":"author_github_handle"},{"location":"prompt_arguments/#project_name","text":"The name of your project. This should match the repository name and contain only alphanumeric characters and hyphens ( - ).","title":"project_name"},{"location":"prompt_arguments/#project_slug","text":"A slug for your project. By default, this is derived from project_name with hyphens ( - ) replaced by underscores ( _ ). This is used for importing code, e.g.: from <project_slug> import foo","title":"project_slug"},{"location":"prompt_arguments/#project_description","text":"A brief description of your project.","title":"project_description"},{"location":"prompt_arguments/#dockerhub_username","text":"Your Docker Hub username, i.e., <handle> in https://hub.docker.com/u/<handle> .","title":"dockerhub_username"},{"location":"prompt_arguments/#include_github_actions","text":"Set this to \"y\" or \"n\" . If enabled, a .github directory will be created with actions and workflows for setting up the environment, running code formatting checks, and executing unit tests.","title":"include_github_actions"},{"location":"prompt_arguments/#data_source_type","text":"Specifies the type of data source for your project. Options: [\"1. Google Drive\"]","title":"data_source_type"},{"location":"prompt_arguments/#data_source_id","text":"The identifier for your data source, such as a folder ID or bucket name, where data is stored for model training.","title":"data_source_id"},{"location":"prompt_arguments/#app_host_port","text":"The port on which the application will run. Defaults to 80 .","title":"app_host_port"},{"location":"prompt_arguments/#open_source_license","text":"Select a license for your project. Options include: [\"1. MIT License\", \"2. BSD license\", \"3. ISC license\", \"4. Apache Software License 2.0\", \"5. GNU General Public License v3\", \"6. Not open source\"]","title":"open_source_license"},{"location":"tutorial/","text":"Tutorial: Setting Up Your Project \u00b6 This guide will walk you through setting up a Python project using the cookiecutter-poetry template, ideal for machine learning development. Follow these steps to get started! Step 1: Install Poetry \u00b6 To begin, you need to install Poetry for dependency management. You can find the installation instructions on the Poetry website . After installing Poetry, it's recommended to configure it to create virtual environments within the project directory: poetry config virtualenvs.in-project true This will ensure that new virtual environments are created inside the ./.venv directory by default whenever you run poetry init . Step 2: Install pyenv (Optional) \u00b6 While this step is optional, pyenv is a useful tool for managing multiple Python versions. If you prefer another method for managing Python versions, feel free to skip this step. To install pyenv, follow the instructions on the pyenv GitHub page . To install a specific Python version with pyenv, run: pyenv install --list # to see available versions pyenv install -v 3.9.7 # replace 3.9.7 with the version you want Step 3: Generate Your Project \u00b6 First, navigate to the directory where you want your project to be created. Then, install the cookiecutter-ml package with the following command: pip install cookiecutter-ml Now, in the desired directory, run: ccp For more information about the prompt arguments, refer to the Prompt Arguments section. Alternatively, you can install cookiecutter and pass the GitHub repository URL directly: pip install cookiecutter-poetry cookiecutter git@github.com:DeepakPant93/cookiecutter-poetry.git Step 4: Set Up Your GitHub Repository \u00b6 Create a new empty repository on GitHub. You can do this by visiting GitHub's new repository page . Make sure the repository name only contains alphanumeric characters and optionally a hyphen ( - ). Do not check any boxes under \"Initialize this repository with\". Step 5: Upload Your Project to GitHub \u00b6 Once your project is ready, run the following commands to upload it to GitHub. Replace <project-name> with the name of your repository, and <github_author_handle> with your GitHub username: cd <project_name> git init -b main git add . git commit -m \"Initial commit\" git remote add origin git@github.com:<github_author_handle>/<project_name>.git git push -u origin main Step 6: Activate Your Environment \u00b6 If you're using pyenv , set the Python version for your project: pyenv local x.y.z # Replace x.y.z with the Python version you want to use Next, install and activate the Poetry environment by running: make bake-env poetry shell Step 7: Sign Up for Codecov \u00b6 If you\u2019ve enabled code coverage in your project, sign up for Codecov using your GitHub account. Step 8: Configure Your Repository Secrets \u00b6 To enable deployment to PyPI via GitHub Actions, you\u2019ll need to configure repository secrets. For detailed instructions, see Setting up for PyPI . Step 9: Create a New Release \u00b6 To trigger a release, go to the Releases tab in your GitHub repository. Click Draft a new release . If you can't find the button, go directly to the URL: https://github.com/<username>/<repository-name>/releases/new . Create a new tag in the format *.*.* , where * represents alphanumeric characters. Finally, click Publish release to trigger the release. Step 10: Enable Documentation \u00b6 To enable documentation with MkDocs on GitHub Pages, navigate to your repository's Settings > Code and Automation > Pages . Once the release is published, you should see a notification saying, Your site is ready to be published at https:// .github.io/ / . Under Source , select the gh-pages branch. Step 11: You're All Set! \u00b6 Congratulations! Your project is now set up and ready for development. The CI/CD pipeline will run automatically when you open a pull request, merge to the main branch, or create a new release. If you have any suggestions for improvements, feel free to open an issue or submit a pull request!","title":"Tutorial"},{"location":"tutorial/#tutorial-setting-up-your-project","text":"This guide will walk you through setting up a Python project using the cookiecutter-poetry template, ideal for machine learning development. Follow these steps to get started!","title":"Tutorial: Setting Up Your Project"},{"location":"tutorial/#step-1-install-poetry","text":"To begin, you need to install Poetry for dependency management. You can find the installation instructions on the Poetry website . After installing Poetry, it's recommended to configure it to create virtual environments within the project directory: poetry config virtualenvs.in-project true This will ensure that new virtual environments are created inside the ./.venv directory by default whenever you run poetry init .","title":"Step 1: Install Poetry"},{"location":"tutorial/#step-2-install-pyenv-optional","text":"While this step is optional, pyenv is a useful tool for managing multiple Python versions. If you prefer another method for managing Python versions, feel free to skip this step. To install pyenv, follow the instructions on the pyenv GitHub page . To install a specific Python version with pyenv, run: pyenv install --list # to see available versions pyenv install -v 3.9.7 # replace 3.9.7 with the version you want","title":"Step 2: Install pyenv (Optional)"},{"location":"tutorial/#step-3-generate-your-project","text":"First, navigate to the directory where you want your project to be created. Then, install the cookiecutter-ml package with the following command: pip install cookiecutter-ml Now, in the desired directory, run: ccp For more information about the prompt arguments, refer to the Prompt Arguments section. Alternatively, you can install cookiecutter and pass the GitHub repository URL directly: pip install cookiecutter-poetry cookiecutter git@github.com:DeepakPant93/cookiecutter-poetry.git","title":"Step 3: Generate Your Project"},{"location":"tutorial/#step-4-set-up-your-github-repository","text":"Create a new empty repository on GitHub. You can do this by visiting GitHub's new repository page . Make sure the repository name only contains alphanumeric characters and optionally a hyphen ( - ). Do not check any boxes under \"Initialize this repository with\".","title":"Step 4: Set Up Your GitHub Repository"},{"location":"tutorial/#step-5-upload-your-project-to-github","text":"Once your project is ready, run the following commands to upload it to GitHub. Replace <project-name> with the name of your repository, and <github_author_handle> with your GitHub username: cd <project_name> git init -b main git add . git commit -m \"Initial commit\" git remote add origin git@github.com:<github_author_handle>/<project_name>.git git push -u origin main","title":"Step 5: Upload Your Project to GitHub"},{"location":"tutorial/#step-6-activate-your-environment","text":"If you're using pyenv , set the Python version for your project: pyenv local x.y.z # Replace x.y.z with the Python version you want to use Next, install and activate the Poetry environment by running: make bake-env poetry shell","title":"Step 6: Activate Your Environment"},{"location":"tutorial/#step-7-sign-up-for-codecov","text":"If you\u2019ve enabled code coverage in your project, sign up for Codecov using your GitHub account.","title":"Step 7: Sign Up for Codecov"},{"location":"tutorial/#step-8-configure-your-repository-secrets","text":"To enable deployment to PyPI via GitHub Actions, you\u2019ll need to configure repository secrets. For detailed instructions, see Setting up for PyPI .","title":"Step 8: Configure Your Repository Secrets"},{"location":"tutorial/#step-9-create-a-new-release","text":"To trigger a release, go to the Releases tab in your GitHub repository. Click Draft a new release . If you can't find the button, go directly to the URL: https://github.com/<username>/<repository-name>/releases/new . Create a new tag in the format *.*.* , where * represents alphanumeric characters. Finally, click Publish release to trigger the release.","title":"Step 9: Create a New Release"},{"location":"tutorial/#step-10-enable-documentation","text":"To enable documentation with MkDocs on GitHub Pages, navigate to your repository's Settings > Code and Automation > Pages . Once the release is published, you should see a notification saying, Your site is ready to be published at https:// .github.io/ / . Under Source , select the gh-pages branch.","title":"Step 10: Enable Documentation"},{"location":"tutorial/#step-11-youre-all-set","text":"Congratulations! Your project is now set up and ready for development. The CI/CD pipeline will run automatically when you open a pull request, merge to the main branch, or create a new release. If you have any suggestions for improvements, feel free to open an issue or submit a pull request!","title":"Step 11: You're All Set!"},{"location":"features/cicd/","text":"CI/CD with Github actions \u00b6 .github directory: .github \u251c\u2500\u2500 actions \u2502 \u2514\u2500\u2500 setup-poetry-env \u2502 \u2514\u2500\u2500 action.yml \u2514\u2500\u2500 workflows \u251c\u2500\u2500 build-and-deploy.yml \u251c\u2500\u2500 deploy-docs.yml \u251c\u2500\u2500 publish-package.yml \u2514\u2500\u2500 test-check-build.yml The .github directory is a special directory in a GitHub repository that contains configuration files related to GitHub-specific features, such as GitHub Actions for CI/CD, issue templates, and pull request templates. In this case, your .github directory is configured to manage CI/CD workflows using GitHub Actions. Here's a detailed explanation of each component and file: .github Directory \u00b6 The .github directory contains subdirectories and files that define custom GitHub workflows and actions to automate tasks like testing, building, deploying, and publishing. 1. actions Subdirectory \u00b6 The actions subdirectory contains reusable custom GitHub Actions. These are defined in YAML files and can be used across your workflows to perform specific tasks. setup-poetry-env Subdirectory \u00b6 This folder contains the configuration for a custom action that is likely used to set up a Python Poetry environment in your workflows. action.yml This is the metadata file that defines the custom to setup a Python Poetry environment. Purpose : This custom action streamlines the setup of the Poetry environment in your workflows, ensuring consistency and reusability. 2. workflows Subdirectory \u00b6 The workflows directory contains YAML files that define GitHub Actions workflows. Each file represents a workflow that automates specific tasks, triggered by events like push , pull_request , or on a schedule. build-and-deploy.yml \u00b6 This workflow automates the build and deployment process for your project. Purpose : Ensures that your application is built correctly and deployed to the intended environment (e.g., staging or production) after passing tests. Typical Steps : Checkout the repository code. Build the project (e.g., compile code or containerize the application). Run tests to verify the build. Deploy the built artifact to the target environment (e.g., a server or cloud platform). deploy-docs.yml \u00b6 This workflow handles the deployment of your project documentation. Purpose : Automates the generation and publishing of documentation to GitHub Pages. Typical Steps : Generate documentation files using a mkdocs. Upload or deploy the generated documentation to GitHub Pages. publish-package.yml \u00b6 This workflow manages the publishing of your package to a PyPI package registry PyPI. Purpose : Automates the process of packaging and releasing your software when a new version is tagged. Typical Steps : Validate versioning (e.g., Semantic Versioning). Build the package (e.g., a Python wheel ). Publish the package to a registry (e.g., PyPI). test-check-build.yml \u00b6 This workflow ensures that your code is tested and validated for quality and correctness. Purpose : Provides a continuous testing pipeline to maintain code integrity. Typical Steps : Run automated tests (e.g., unit tests, integration tests). Check code quality (e.g., using linters like flake8 or eslint ). Verify that the project builds successfully. Summary \u00b6 Your .github directory is structured to manage and automate critical development tasks through GitHub Actions. Here's a quick overview: Custom Action ( setup-poetry-env ) : Provides reusable functionality for setting up a Poetry environment. Workflows : build-and-deploy.yml : Automates application building and deployment. deploy-docs.yml : Manages the deployment of project documentation. publish-package.yml : Handles publishing of your package to a registry. test-check-build.yml : Ensures code quality and integrity through automated testing and validation. These configurations enable streamlined CI/CD processes, improving development efficiency and maintaining high-quality code practices.","title":"CI/CD with Github Actions"},{"location":"features/cicd/#cicd-with-github-actions","text":".github directory: .github \u251c\u2500\u2500 actions \u2502 \u2514\u2500\u2500 setup-poetry-env \u2502 \u2514\u2500\u2500 action.yml \u2514\u2500\u2500 workflows \u251c\u2500\u2500 build-and-deploy.yml \u251c\u2500\u2500 deploy-docs.yml \u251c\u2500\u2500 publish-package.yml \u2514\u2500\u2500 test-check-build.yml The .github directory is a special directory in a GitHub repository that contains configuration files related to GitHub-specific features, such as GitHub Actions for CI/CD, issue templates, and pull request templates. In this case, your .github directory is configured to manage CI/CD workflows using GitHub Actions. Here's a detailed explanation of each component and file:","title":"CI/CD with Github actions"},{"location":"features/cicd/#github-directory","text":"The .github directory contains subdirectories and files that define custom GitHub workflows and actions to automate tasks like testing, building, deploying, and publishing.","title":".github Directory"},{"location":"features/cicd/#1-actions-subdirectory","text":"The actions subdirectory contains reusable custom GitHub Actions. These are defined in YAML files and can be used across your workflows to perform specific tasks.","title":"1. actions Subdirectory"},{"location":"features/cicd/#setup-poetry-env-subdirectory","text":"This folder contains the configuration for a custom action that is likely used to set up a Python Poetry environment in your workflows. action.yml This is the metadata file that defines the custom to setup a Python Poetry environment. Purpose : This custom action streamlines the setup of the Poetry environment in your workflows, ensuring consistency and reusability.","title":"setup-poetry-env Subdirectory"},{"location":"features/cicd/#2-workflows-subdirectory","text":"The workflows directory contains YAML files that define GitHub Actions workflows. Each file represents a workflow that automates specific tasks, triggered by events like push , pull_request , or on a schedule.","title":"2. workflows Subdirectory"},{"location":"features/cicd/#build-and-deployyml","text":"This workflow automates the build and deployment process for your project. Purpose : Ensures that your application is built correctly and deployed to the intended environment (e.g., staging or production) after passing tests. Typical Steps : Checkout the repository code. Build the project (e.g., compile code or containerize the application). Run tests to verify the build. Deploy the built artifact to the target environment (e.g., a server or cloud platform).","title":"build-and-deploy.yml"},{"location":"features/cicd/#deploy-docsyml","text":"This workflow handles the deployment of your project documentation. Purpose : Automates the generation and publishing of documentation to GitHub Pages. Typical Steps : Generate documentation files using a mkdocs. Upload or deploy the generated documentation to GitHub Pages.","title":"deploy-docs.yml"},{"location":"features/cicd/#publish-packageyml","text":"This workflow manages the publishing of your package to a PyPI package registry PyPI. Purpose : Automates the process of packaging and releasing your software when a new version is tagged. Typical Steps : Validate versioning (e.g., Semantic Versioning). Build the package (e.g., a Python wheel ). Publish the package to a registry (e.g., PyPI).","title":"publish-package.yml"},{"location":"features/cicd/#test-check-buildyml","text":"This workflow ensures that your code is tested and validated for quality and correctness. Purpose : Provides a continuous testing pipeline to maintain code integrity. Typical Steps : Run automated tests (e.g., unit tests, integration tests). Check code quality (e.g., using linters like flake8 or eslint ). Verify that the project builds successfully.","title":"test-check-build.yml"},{"location":"features/cicd/#summary","text":"Your .github directory is structured to manage and automate critical development tasks through GitHub Actions. Here's a quick overview: Custom Action ( setup-poetry-env ) : Provides reusable functionality for setting up a Poetry environment. Workflows : build-and-deploy.yml : Automates application building and deployment. deploy-docs.yml : Manages the deployment of project documentation. publish-package.yml : Handles publishing of your package to a registry. test-check-build.yml : Ensures code quality and integrity through automated testing and validation. These configurations enable streamlined CI/CD processes, improving development efficiency and maintaining high-quality code practices.","title":"Summary"},{"location":"features/codecov/","text":"Test Coverage with Codecov \u00b6 Executing make test runs the test suite and generates a coverage report in the form of coverage.xml . Integration with Codecov has been added to the CI/CD pipeline for comprehensive test coverage analysis. To enable Codecov: Sign up at Codecov.io using your GitHub account. Include a codecov.yaml configuration file in your repository with the following default settings: Generate a new token at Codecov.io and add it to the github secret as CODECOV_TOKEN . # Badge color changes from red to green between 70% and 100% # PR pipeline fails if codecov falls with 1% coverage: range: 70..100 round: down precision: 1 status: project: default: target: auto threshold: 1%","title":"Test coverage with codecov"},{"location":"features/codecov/#test-coverage-with-codecov","text":"Executing make test runs the test suite and generates a coverage report in the form of coverage.xml . Integration with Codecov has been added to the CI/CD pipeline for comprehensive test coverage analysis. To enable Codecov: Sign up at Codecov.io using your GitHub account. Include a codecov.yaml configuration file in your repository with the following default settings: Generate a new token at Codecov.io and add it to the github secret as CODECOV_TOKEN . # Badge color changes from red to green between 70% and 100% # PR pipeline fails if codecov falls with 1% coverage: range: 70..100 round: down precision: 1 status: project: default: target: auto threshold: 1%","title":"Test Coverage with Codecov"},{"location":"features/deployment/","text":"Deployment with Azure Container App \u00b6 To deploy your application to Azure Container Apps, follow these steps: Step 1: Add DOCKERHUB_PUSH_TOKEN to GitHub Secrets \u00b6 To push the image to Docker Hub in the CI/CD pipeline, add the DOCKERHUB_PUSH_TOKEN as a GitHub secret. This token allows GitHub Actions to authenticate with Docker Hub for pushing the Docker image. Step 2: Add AZURE_CREDENTIALS to GitHub Secrets \u00b6 In order to log in to Azure and deploy the container app, you need to provide Azure credentials. Add AZURE_CREDENTIALS to your GitHub secrets. This credential will allow the CI/CD pipeline to authenticate and interact with Azure resources. You can obtain the necessary Azure credentials by setting up the Azure CLI and following the instructions provided by Microsoft: Install the Azure CLI from this link . Once the Azure CLI is installed and configured, you can generate the Azure credentials JSON file for GitHub secrets. Step 3: Generate Azure Credentials \u00b6 Run the following command to set up the Azure Container App and create the Service Principal : make setup-cloud-env This will generate an output JSON, which contains the Azure credentials required for deployment. The JSON will look like this: { \"clientId\": \"<clientId>\", \"clientSecret\": \"<ClientSecret>\", \"subscriptionId\": \"<subscriptionId>\", \"tenantId\": \"<tenentId>\", \"activeDirectoryEndpointUrl\": \"https://login.microsoftonline.com\", \"resourceManagerEndpointUrl\": \"https://management.azure.com/\", \"activeDirectoryGraphResourceId\": \"https://graph.windows.net/\", \"sqlManagementEndpointUrl\": \"https://management.core.windows.net:8443/\", \"galleryEndpointUrl\": \"https://gallery.azure.com/\", \"managementEndpointUrl\": \"https://management.core.windows.net/\" } Step 4: Add Azure Credentials to GitHub Secrets \u00b6 Once you have the JSON, add it to GitHub as the secret AZURE_CREDENTIALS : Go to your GitHub repository. Navigate to Settings > Secrets > New repository secret . Name the secret AZURE_CREDENTIALS and paste the entire JSON content into the value field. Step 5: Deploy the Container App \u00b6 After the credentials are set up, the application will automatically be deployed to Azure after each release. This is handled by the CI/CD pipeline in GitHub Actions. During the container app setup, the make setup-cloud-env command will also provide you with a URL for your deployed app. You can use this URL to access the live application once deployed. Further Reading \u00b6 You can explore more about Azure Container Apps in the official documentation here: Azure Container Apps Documentation .","title":"Deployment with Azure Container Apps"},{"location":"features/deployment/#deployment-with-azure-container-app","text":"To deploy your application to Azure Container Apps, follow these steps:","title":"Deployment with Azure Container App"},{"location":"features/deployment/#step-1-add-dockerhub_push_token-to-github-secrets","text":"To push the image to Docker Hub in the CI/CD pipeline, add the DOCKERHUB_PUSH_TOKEN as a GitHub secret. This token allows GitHub Actions to authenticate with Docker Hub for pushing the Docker image.","title":"Step 1: Add DOCKERHUB_PUSH_TOKEN to GitHub Secrets"},{"location":"features/deployment/#step-2-add-azure_credentials-to-github-secrets","text":"In order to log in to Azure and deploy the container app, you need to provide Azure credentials. Add AZURE_CREDENTIALS to your GitHub secrets. This credential will allow the CI/CD pipeline to authenticate and interact with Azure resources. You can obtain the necessary Azure credentials by setting up the Azure CLI and following the instructions provided by Microsoft: Install the Azure CLI from this link . Once the Azure CLI is installed and configured, you can generate the Azure credentials JSON file for GitHub secrets.","title":"Step 2: Add AZURE_CREDENTIALS to GitHub Secrets"},{"location":"features/deployment/#step-3-generate-azure-credentials","text":"Run the following command to set up the Azure Container App and create the Service Principal : make setup-cloud-env This will generate an output JSON, which contains the Azure credentials required for deployment. The JSON will look like this: { \"clientId\": \"<clientId>\", \"clientSecret\": \"<ClientSecret>\", \"subscriptionId\": \"<subscriptionId>\", \"tenantId\": \"<tenentId>\", \"activeDirectoryEndpointUrl\": \"https://login.microsoftonline.com\", \"resourceManagerEndpointUrl\": \"https://management.azure.com/\", \"activeDirectoryGraphResourceId\": \"https://graph.windows.net/\", \"sqlManagementEndpointUrl\": \"https://management.core.windows.net:8443/\", \"galleryEndpointUrl\": \"https://gallery.azure.com/\", \"managementEndpointUrl\": \"https://management.core.windows.net/\" }","title":"Step 3: Generate Azure Credentials"},{"location":"features/deployment/#step-4-add-azure-credentials-to-github-secrets","text":"Once you have the JSON, add it to GitHub as the secret AZURE_CREDENTIALS : Go to your GitHub repository. Navigate to Settings > Secrets > New repository secret . Name the secret AZURE_CREDENTIALS and paste the entire JSON content into the value field.","title":"Step 4: Add Azure Credentials to GitHub Secrets"},{"location":"features/deployment/#step-5-deploy-the-container-app","text":"After the credentials are set up, the application will automatically be deployed to Azure after each release. This is handled by the CI/CD pipeline in GitHub Actions. During the container app setup, the make setup-cloud-env command will also provide you with a URL for your deployed app. You can use this URL to access the live application once deployed.","title":"Step 5: Deploy the Container App"},{"location":"features/deployment/#further-reading","text":"You can explore more about Azure Container Apps in the official documentation here: Azure Container Apps Documentation .","title":"Further Reading"},{"location":"features/devcontainer/","text":"Reproducible Development Environments with VSCode DevContainers \u00b6 This project includes a devcontainer configuration located in the .devcontainer directory. The devcontainer utilizes the VSCode devcontainer specification to create a consistent and reproducible development environment. It pre-installs all dependencies, including those required by Poetry, for project development, testing, and building. Additionally, the devcontainer sets up pre-commit hooks and configures the VSCode Python extension to use the correct Python interpreter and pytest paths.","title":"Devcontainer with VSCode"},{"location":"features/devcontainer/#reproducible-development-environments-with-vscode-devcontainers","text":"This project includes a devcontainer configuration located in the .devcontainer directory. The devcontainer utilizes the VSCode devcontainer specification to create a consistent and reproducible development environment. It pre-installs all dependencies, including those required by Poetry, for project development, testing, and building. Additionally, the devcontainer sets up pre-commit hooks and configures the VSCode Python extension to use the correct Python interpreter and pytest paths.","title":"Reproducible Development Environments with VSCode DevContainers"},{"location":"features/docker/","text":"Containerization with Docker \u00b6 This project includes a Dockerfile in the root directory, which installs Poetry, sets up the environment, and runs main.py when executed. To build the Docker image, use the following command: docker build . -t my-docker-image Once the image is built, it can be run in the background using: docker run -d my-docker-image Alternatively, to run the container in interactive mode, use: docker run --rm -it --entrypoint bash my-docker-image","title":"Containerization with Docker"},{"location":"features/docker/#containerization-with-docker","text":"This project includes a Dockerfile in the root directory, which installs Poetry, sets up the environment, and runs main.py when executed. To build the Docker image, use the following command: docker build . -t my-docker-image Once the image is built, it can be run in the background using: docker run -d my-docker-image Alternatively, to run the container in interactive mode, use: docker run --rm -it --entrypoint bash my-docker-image","title":"Containerization with Docker"},{"location":"features/dvc/","text":"Data Version Control (DVC) with Google Drive as Remote Storage \u00b6 In this application, we are using DVC (Data Version Control) to track changes in our data. DVC allows us to version control large data files, enabling easy collaboration and versioning of datasets. For this application, we are using Google Drive as the remote storage for DVC. Setting Up Google Drive as Remote Storage for DVC \u00b6 To use Google Drive as a remote storage in DVC, follow these steps: Create a Folder in Google Drive Create a new folder in your Google Drive where the data will be stored. Set Folder Permissions Change the folder's permissions to \"Anyone with the link\" and grant read and write access to allow DVC to interact with the folder. Get Folder ID The folder ID will be part of the Google Drive folder URL (e.g., https://drive.google.com/drive/folders/<folder_id> ). Use this folder ID as the data_source_id for the application. Install Google Cloud SDK Install the Google Cloud SDK on your local machine to manage authentication and interact with Google Cloud services. Create a Service Account After installing the Google Cloud SDK, create a service account and assign the necessary permissions to access Google Drive. Run DVC Setup Command Run the following command to set up Google Drive as the remote storage for DVC: make bake-dvc This command will configure DVC to use your Google Drive folder as the remote storage. Using DVC to Manage Data \u00b6 Once the remote storage is set up, you can start managing your data using DVC. The following commands are used to add, push, and pull data: Add Data to DVC : Add a data file to both DVC and Git, and enable auto-stage in DVC: dvc add <data_file> Push Data to Git and DVC Remote : Push the changes to both Git and the remote storage (Google Drive): dvc push Pull Data from Git and DVC Remote : Pull the data from both Git and the remote storage: dvc pull Running the DVC Pipeline \u00b6 To execute the DVC pipeline, use the following command. The pipeline will run the code specified in the dvc.yaml file: dvc run <pipeline_name> This will trigger the pipeline defined in the dvc.yaml file, where various steps and commands for data processing and training are outlined. Conclusion \u00b6 With these steps, you can effectively use DVC for managing and versioning your data in Google Drive. By integrating DVC with your workflow, you can ensure reproducibility and collaboration in managing large datasets.","title":"Data Version Control with DVC"},{"location":"features/dvc/#data-version-control-dvc-with-google-drive-as-remote-storage","text":"In this application, we are using DVC (Data Version Control) to track changes in our data. DVC allows us to version control large data files, enabling easy collaboration and versioning of datasets. For this application, we are using Google Drive as the remote storage for DVC.","title":"Data Version Control (DVC) with Google Drive as Remote Storage"},{"location":"features/dvc/#setting-up-google-drive-as-remote-storage-for-dvc","text":"To use Google Drive as a remote storage in DVC, follow these steps: Create a Folder in Google Drive Create a new folder in your Google Drive where the data will be stored. Set Folder Permissions Change the folder's permissions to \"Anyone with the link\" and grant read and write access to allow DVC to interact with the folder. Get Folder ID The folder ID will be part of the Google Drive folder URL (e.g., https://drive.google.com/drive/folders/<folder_id> ). Use this folder ID as the data_source_id for the application. Install Google Cloud SDK Install the Google Cloud SDK on your local machine to manage authentication and interact with Google Cloud services. Create a Service Account After installing the Google Cloud SDK, create a service account and assign the necessary permissions to access Google Drive. Run DVC Setup Command Run the following command to set up Google Drive as the remote storage for DVC: make bake-dvc This command will configure DVC to use your Google Drive folder as the remote storage.","title":"Setting Up Google Drive as Remote Storage for DVC"},{"location":"features/dvc/#using-dvc-to-manage-data","text":"Once the remote storage is set up, you can start managing your data using DVC. The following commands are used to add, push, and pull data: Add Data to DVC : Add a data file to both DVC and Git, and enable auto-stage in DVC: dvc add <data_file> Push Data to Git and DVC Remote : Push the changes to both Git and the remote storage (Google Drive): dvc push Pull Data from Git and DVC Remote : Pull the data from both Git and the remote storage: dvc pull","title":"Using DVC to Manage Data"},{"location":"features/dvc/#running-the-dvc-pipeline","text":"To execute the DVC pipeline, use the following command. The pipeline will run the code specified in the dvc.yaml file: dvc run <pipeline_name> This will trigger the pipeline defined in the dvc.yaml file, where various steps and commands for data processing and training are outlined.","title":"Running the DVC Pipeline"},{"location":"features/dvc/#conclusion","text":"With these steps, you can effectively use DVC for managing and versioning your data in Google Drive. By integrating DVC with your workflow, you can ensure reproducibility and collaboration in managing large datasets.","title":"Conclusion"},{"location":"features/linting/","text":"Linting and code quality \u00b6 Code can be linted and quality-checked with the command make lint Note that this requires the pre-commit hooks to be installed. This command will run the following tools: ruff \u00b6 ruff is used to lint and format the code, and it is configured through pyproject.toml : [tool.ruff] target-version = \"py37\" line-length = 120 fix = false select = [ # flake8-2020 \"YTT\", # flake8-bandit \"S\", # flake8-bugbear \"B\", # flake8-builtins \"A\", # flake8-comprehensions \"C4\", # flake8-debugger \"T10\", # flake8-print \"T20\", # flake8-simplify \"SIM\", # isort \"I\", # mccabe \"C90\", # pycodestyle \"E\", \"W\", # pyflakes \"F\", # pygrep-hooks \"PGH\", # pyupgrade \"UP\", # ruff \"RUF\", # tryceratops \"TRY\", ] ignore = [ # LineTooLong \"E501\", # DoNotAssignLambda \"E731\", ] [tool.ruff.per-file-ignores] \"tests/*\" = [\"S101\"] Typechecking \u00b6 mypy is used for static type checking. mypy \u00b6 mypy can be used for static type checking, and its configuration and can be edited in pyproject.toml . [tool.mypy] disallow_untyped_defs = \"True\" disallow_any_unimported = \"True\" no_implicit_optional = \"True\" check_untyped_defs = \"True\" warn_return_any = \"True\" warn_unused_ignores = \"True\" show_error_codes = \"True\" exclude = [ '\\.venv', '{{cookiecutter.project_name}}', 'tests' ] deptry \u00b6 deptry is used to check the code for dependency issues, and its configuration and can be edited in pyproject.toml . [tool.mypy] disallow_untyped_defs = \"True\" disallow_any_unimported = \"True\" no_implicit_optional = \"True\" check_untyped_defs = \"True\" warn_return_any = \"True\" warn_unused_ignores = \"True\" show_error_codes = \"True\" exclude = [ '\\.venv', '{{cookiecutter.project_name}}', 'tests' ] Prettier \u00b6 Prettier is used to format the markdown documentation, along with any json and yaml files. Its options can be configured in the included .editorconfig file or in greater detail by adding a .prettierrc file ( See Docs ). [*] max_line_length = 120 [*.json] indent_style = space indent_size = 4 Github Actions \u00b6 The code formatting is checked for every merge request, every merge to main, and every release.","title":"Linting & code quality"},{"location":"features/linting/#linting-and-code-quality","text":"Code can be linted and quality-checked with the command make lint Note that this requires the pre-commit hooks to be installed. This command will run the following tools:","title":"Linting and code quality"},{"location":"features/linting/#ruff","text":"ruff is used to lint and format the code, and it is configured through pyproject.toml : [tool.ruff] target-version = \"py37\" line-length = 120 fix = false select = [ # flake8-2020 \"YTT\", # flake8-bandit \"S\", # flake8-bugbear \"B\", # flake8-builtins \"A\", # flake8-comprehensions \"C4\", # flake8-debugger \"T10\", # flake8-print \"T20\", # flake8-simplify \"SIM\", # isort \"I\", # mccabe \"C90\", # pycodestyle \"E\", \"W\", # pyflakes \"F\", # pygrep-hooks \"PGH\", # pyupgrade \"UP\", # ruff \"RUF\", # tryceratops \"TRY\", ] ignore = [ # LineTooLong \"E501\", # DoNotAssignLambda \"E731\", ] [tool.ruff.per-file-ignores] \"tests/*\" = [\"S101\"]","title":"ruff"},{"location":"features/linting/#typechecking","text":"mypy is used for static type checking.","title":"Typechecking"},{"location":"features/linting/#mypy","text":"mypy can be used for static type checking, and its configuration and can be edited in pyproject.toml . [tool.mypy] disallow_untyped_defs = \"True\" disallow_any_unimported = \"True\" no_implicit_optional = \"True\" check_untyped_defs = \"True\" warn_return_any = \"True\" warn_unused_ignores = \"True\" show_error_codes = \"True\" exclude = [ '\\.venv', '{{cookiecutter.project_name}}', 'tests' ]","title":"mypy"},{"location":"features/linting/#deptry","text":"deptry is used to check the code for dependency issues, and its configuration and can be edited in pyproject.toml . [tool.mypy] disallow_untyped_defs = \"True\" disallow_any_unimported = \"True\" no_implicit_optional = \"True\" check_untyped_defs = \"True\" warn_return_any = \"True\" warn_unused_ignores = \"True\" show_error_codes = \"True\" exclude = [ '\\.venv', '{{cookiecutter.project_name}}', 'tests' ]","title":"deptry"},{"location":"features/linting/#prettier","text":"Prettier is used to format the markdown documentation, along with any json and yaml files. Its options can be configured in the included .editorconfig file or in greater detail by adding a .prettierrc file ( See Docs ). [*] max_line_length = 120 [*.json] indent_style = space indent_size = 4","title":"Prettier"},{"location":"features/linting/#github-actions","text":"The code formatting is checked for every merge request, every merge to main, and every release.","title":"Github Actions"},{"location":"features/makefile/","text":"Makefile \u00b6 The generated repository will have a Makefile available. A list of all available commands that are available can be obtained by running make help in the terminal. Initially, if all features are selected, the following commands are available: help Display this help message bake-env Install the poetry environment and set up pre-commit hooks clean-env Remove the poetry environment reset-env Install the poetry environment and set up pre-commit hooks init-repo Initialize git repository setup-cloud-env Create resource group, container app environment, and service principal clean-cloud-env Delete resource group, container app environment, and service principal bake-dvc Initialize DVC and set up service account clean-dvc Clean up DVC and service account lint Run code quality tools test Run tests with pytest bake Build wheel file using poetry clean-bake Clean build artifacts publish Publish a release to PyPI bake-and-publish Build and publish to PyPI update Update project dependencies run Run the project's main application docs-test Test if documentation can be built without warnings or errors docs Build and serve the documentation bake-container Build Docker image container-push Push Docker image to Docker Hub bake-container-and-push Build and push Docker image to Docker Hub clean-container Clean up Docker resources related to the app dvc-add-data Add a data file to DVC and Git, and enable autostage in DVC dvc-push-data Push changes to Git dvc-pull-data Push changes to Git dvc-run-pipeline Run DVC pipeline print-dependency-tree Initialize DVC and set up service account teardown Clean up temporary files and directories and destroy the virtual environment, Docker image from your local machine teardown-all Clean up temporary files and directories and destroy the virtual environment, Docker image, and Cloud resources","title":"Makefile"},{"location":"features/makefile/#makefile","text":"The generated repository will have a Makefile available. A list of all available commands that are available can be obtained by running make help in the terminal. Initially, if all features are selected, the following commands are available: help Display this help message bake-env Install the poetry environment and set up pre-commit hooks clean-env Remove the poetry environment reset-env Install the poetry environment and set up pre-commit hooks init-repo Initialize git repository setup-cloud-env Create resource group, container app environment, and service principal clean-cloud-env Delete resource group, container app environment, and service principal bake-dvc Initialize DVC and set up service account clean-dvc Clean up DVC and service account lint Run code quality tools test Run tests with pytest bake Build wheel file using poetry clean-bake Clean build artifacts publish Publish a release to PyPI bake-and-publish Build and publish to PyPI update Update project dependencies run Run the project's main application docs-test Test if documentation can be built without warnings or errors docs Build and serve the documentation bake-container Build Docker image container-push Push Docker image to Docker Hub bake-container-and-push Build and push Docker image to Docker Hub clean-container Clean up Docker resources related to the app dvc-add-data Add a data file to DVC and Git, and enable autostage in DVC dvc-push-data Push changes to Git dvc-pull-data Push changes to Git dvc-run-pipeline Run DVC pipeline print-dependency-tree Initialize DVC and set up service account teardown Clean up temporary files and directories and destroy the virtual environment, Docker image from your local machine teardown-all Clean up temporary files and directories and destroy the virtual environment, Docker image, and Cloud resources","title":"Makefile"},{"location":"features/mkdocs/","text":"Documentation with MkDocs \u00b6 Project documentation is automatically generated using MkDocs . If \"include_github_actions\" is set to \"y\" , the documentation is automatically deployed to the gh-pages branch and is accessible at https://<github_handle>.github.io/<project_name>/ . To view the documentation locally, run the following command: make docs This will generate and build the documentation, and start a local server, making it accessible at http://localhost:8000 . Enabling Documentation on GitHub \u00b6 To enable documentation on GitHub: Go to Settings > Actions > General , and under Workflow permissions , select Read and write permissions . Create a new release for your project. Navigate to Settings > Code and Automation > Pages . If the release was successfully created, you should see a notification saying Your site is ready to be published at https://<author_github_handle>.github.io/<project_name>/ . Under Source , select the gh-pages branch. Your documentation should go live within a few minutes. Documenting Docstrings \u00b6 The project automatically converts all docstrings into readable documentation. By default, the project is configured to use Google style docstrings. Here is an example of a Google-style docstring: def function_with_pep484_type_annotations(param1: int, param2: str) -> bool: \"\"\"Example function with PEP 484 type annotations. Args: param1: The first parameter. param2: The second parameter. Returns: The return value. True for success, False otherwise. \"\"\" For more examples, refer to the Napoleon documentation .","title":"Documentation with MkDocs"},{"location":"features/mkdocs/#documentation-with-mkdocs","text":"Project documentation is automatically generated using MkDocs . If \"include_github_actions\" is set to \"y\" , the documentation is automatically deployed to the gh-pages branch and is accessible at https://<github_handle>.github.io/<project_name>/ . To view the documentation locally, run the following command: make docs This will generate and build the documentation, and start a local server, making it accessible at http://localhost:8000 .","title":"Documentation with MkDocs"},{"location":"features/mkdocs/#enabling-documentation-on-github","text":"To enable documentation on GitHub: Go to Settings > Actions > General , and under Workflow permissions , select Read and write permissions . Create a new release for your project. Navigate to Settings > Code and Automation > Pages . If the release was successfully created, you should see a notification saying Your site is ready to be published at https://<author_github_handle>.github.io/<project_name>/ . Under Source , select the gh-pages branch. Your documentation should go live within a few minutes.","title":"Enabling Documentation on GitHub"},{"location":"features/mkdocs/#documenting-docstrings","text":"The project automatically converts all docstrings into readable documentation. By default, the project is configured to use Google style docstrings. Here is an example of a Google-style docstring: def function_with_pep484_type_annotations(param1: int, param2: str) -> bool: \"\"\"Example function with PEP 484 type annotations. Args: param1: The first parameter. param2: The second parameter. Returns: The return value. True for success, False otherwise. \"\"\" For more examples, refer to the Napoleon documentation .","title":"Documenting Docstrings"},{"location":"features/poetry/","text":"Dependency Management with Poetry \u00b6 The generated repository uses Poetry for dependency management. Once you've created your repository using this cookiecutter template, a Poetry environment is pre-configured in the pyproject.toml and poetry.toml files. To add project-specific dependencies, run: poetry add <package> Then, install the environment by running: make bake-env By default, the environment is created in a .venv folder. You can easily start an interactive shell within the environment using: poetry shell","title":"Dependency management with Poetry"},{"location":"features/poetry/#dependency-management-with-poetry","text":"The generated repository uses Poetry for dependency management. Once you've created your repository using this cookiecutter template, a Poetry environment is pre-configured in the pyproject.toml and poetry.toml files. To add project-specific dependencies, run: poetry add <package> Then, install the environment by running: make bake-env By default, the environment is created in a .venv folder. You can easily start an interactive shell within the environment using: poetry shell","title":"Dependency Management with Poetry"},{"location":"features/publishing/","text":"Publishing to PyPI or Artifactory \u00b6 Releasing from GitHub \u00b6 To successfully publish your project from the release workflow, you'll need to add some secrets to your GitHub repository so they can be used as environment variables. Set-up for PyPI \u00b6 To publish to PyPI, you'll need to set the secret PYPI_TOKEN in your repository. Here's how to do it: Navigate to Settings > Secrets > Actions in your GitHub repository and click New repository secret . Name the secret PYPI_TOKEN . In a new tab, go to your PyPI Account settings and select Add API token . Copy the token and paste it into the Value field for the GitHub secret you created in the previous step. You're all set! Publishing from Your Local Machine \u00b6 While it is possible to release locally, it is not recommended. If you choose to release locally, set the repository secrets as environment variables on your local machine and run: make bake-and-publish","title":"Publishing to PyPI"},{"location":"features/publishing/#publishing-to-pypi-or-artifactory","text":"","title":"Publishing to PyPI or Artifactory"},{"location":"features/publishing/#releasing-from-github","text":"To successfully publish your project from the release workflow, you'll need to add some secrets to your GitHub repository so they can be used as environment variables.","title":"Releasing from GitHub"},{"location":"features/publishing/#set-up-for-pypi","text":"To publish to PyPI, you'll need to set the secret PYPI_TOKEN in your repository. Here's how to do it: Navigate to Settings > Secrets > Actions in your GitHub repository and click New repository secret . Name the secret PYPI_TOKEN . In a new tab, go to your PyPI Account settings and select Add API token . Copy the token and paste it into the Value field for the GitHub secret you created in the previous step. You're all set!","title":"Set-up for PyPI"},{"location":"features/publishing/#publishing-from-your-local-machine","text":"While it is possible to release locally, it is not recommended. If you choose to release locally, set the repository secrets as environment variables on your local machine and run: make bake-and-publish","title":"Publishing from Your Local Machine"},{"location":"features/pytest/","text":"Unit Testing with Pytest \u00b6 Pytest is automatically included in the environment. A template unit test is created in the tests directory when the project is set up. You can run the tests using: make test If include_github_actions is set to \"y\" , the tests will automatically run for every merge request, merge to the main branch, and release.","title":"Testing with Pytest"},{"location":"features/pytest/#unit-testing-with-pytest","text":"Pytest is automatically included in the environment. A template unit test is created in the tests directory when the project is set up. You can run the tests using: make test If include_github_actions is set to \"y\" , the tests will automatically run for every merge request, merge to the main branch, and release.","title":"Unit Testing with Pytest"},{"location":"features/tox/","text":"Compatibility Testing with Tox \u00b6 This project uses Tox to test compatibility across multiple Python versions. By default, the project is tested with Python versions 3.10 , 3.11 , and 3.12 . The tests are automatically run in the CI/CD pipeline on every pull request, merge to the main branch, and release. To add more Python versions, simply update the tox.ini file and modify the relevant workflows in the .github directory.","title":"Compatibility testing with Tox"},{"location":"features/tox/#compatibility-testing-with-tox","text":"This project uses Tox to test compatibility across multiple Python versions. By default, the project is tested with Python versions 3.10 , 3.11 , and 3.12 . The tests are automatically run in the CI/CD pipeline on every pull request, merge to the main branch, and release. To add more Python versions, simply update the tox.ini file and modify the relevant workflows in the .github directory.","title":"Compatibility Testing with Tox"}]}